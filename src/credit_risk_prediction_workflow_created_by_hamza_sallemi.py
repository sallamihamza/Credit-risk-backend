# -*- coding: utf-8 -*-
"""Credit Risk Prediction Workflow created by Hamza sallemi

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1olQmofQlbH6ouVTlEL8vhFUKTBI5K3IT

# üíª ***Code Explanation: Credit Risk Prediction Workflow***
This code block performs several key steps in a typical machine learning pipeline used for credit risk prediction, including data loading, preprocessing, model training, evaluation, and saving the best model. It is particularly relevant in domains like finance and credit scoring, aligning well with ***Hamza Sallemi***‚Äôs interests in data science and fintech.

# 1. Importing Libraries
"""

# üì¶ Data Manipulation
import pandas as pd  # For loading and handling tabular data
import numpy as np   # For numerical operations

# üß™ Data Preprocessing & Splitting
from sklearn.model_selection import train_test_split, GridSearchCV  # For train-test split and hyperparameter tuning
from sklearn.preprocessing import StandardScaler, OneHotEncoder     # For scaling numeric features and encoding categoricals
from sklearn.compose import ColumnTransformer                       # To apply different preprocessing to different columns
from sklearn.pipeline import Pipeline                               # To chain preprocessing and modeling steps

# ü§ñ Machine Learning Models
from sklearn.linear_model import LogisticRegression                 # Logistic Regression classifier
from sklearn.ensemble import RandomForestClassifier                 # Random Forest classifier
from xgboost import XGBClassifier                                   # XGBoost classifier

# üìà Model Evaluation Metrics
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, roc_auc_score,
    classification_report, confusion_matrix
)

# üíæ Model Saving
import joblib  # To save and load trained models

"""## üìö Why These Libraries?

This notebook uses a set of core libraries to build a complete machine learning pipeline for credit risk prediction:

- **pandas & numpy**: For data loading, analysis, and numerical operations.
- **scikit-learn (sklearn)**:
  - `train_test_split`, `GridSearchCV`: Data splitting and hyperparameter tuning.
  - `StandardScaler`, `OneHotEncoder`: Preprocessing for numerical and categorical features.
  - `ColumnTransformer`, `Pipeline`: Modular and efficient data handling.
  - `LogisticRegression`, `RandomForestClassifier`: Widely used classifiers in finance.
  - `metrics`: For evaluating model accuracy, precision, recall, AUC, and more.
- **xgboost**: High-performance gradient boosting framework, often used in credit scoring.
- **joblib**: Saves the full pipeline (model + preprocessing) for reuse in production.

This setup ensures a robust, interpretable, and scalable model development process aligned with real-world financial applications.

# 2. Data Loading or Dummy Data Generation
"""

# --- Data Loading (Added for completeness - assume loan_data.csv exists) ---
# In a real scenario, this would come from your data collection/preprocessing step.
# For demonstration, let's create a dummy dataset if loan_data.csv doesn't exist.
try:
    df = pd.read_csv('loan_data.csv')
except FileNotFoundError:
    print("loan_data.csv not found. Generating a dummy dataset for demonstration.")
    data = {
        'person_age': np.random.randint(18, 70, 1000),
        'person_income': np.random.randint(15000, 150000, 1000),
        'person_emp_exp': np.random.randint(0, 40, 1000),
        'loan_amnt': np.random.randint(1000, 35000, 1000),
        'loan_int_rate': np.random.uniform(5.0, 20.0, 1000),
        'loan_percent_income': np.random.uniform(0.05, 0.7, 1000),
        'cb_person_cred_hist_length': np.random.randint(0, 30, 1000),
        'credit_score': np.random.randint(300, 850, 1000),
        'person_gender': np.random.choice(['Male', 'Female'], 1000),
        'person_education': np.random.choice(['High School', 'Bachelor', 'Master', 'Doctorate'], 1000),
        'person_home_ownership': np.random.choice(['RENT', 'OWN', 'MORTGAGE', 'OTHER'], 1000),
        'loan_intent': np.random.choice(['PERSONAL', 'EDUCATION', 'MEDICAL', 'VENTURE', 'HOMEIMPROVEMENT', 'DEBTCONSOLIDATION'], 1000),
        'previous_loan_defaults_on_file': np.random.choice(['No', 'Yes'], 1000, p=[0.8, 0.2]),
        'loan_status': np.random.choice([0, 1], 1000, p=[0.7, 0.3]) # 0: No Risk, 1: High Risk
    }
    df = pd.DataFrame(data)
    df.to_csv('loan_data.csv', index=False)
    print("Dummy loan_data.csv created.")

"""This part attempts to load data from a CSV file named loan_data.csv. If the file is not found, it generates a dummy dataset with 1000 rows and several columns representing loan and personal information, including a loan_status column indicating risk (0 for no risk, 1 for high risk). This dummy data allows the code to run even without a real dataset, which is helpful for demonstration or testing. The generated dummy data is then saved to loan_data.csv.

# 3. Defining Target and Features
"""

# Define target and features
TARGET = 'loan_status'
FEATURES = [col for col in df.columns if col != TARGET]

X = df[FEATURES]
y = df[TARGET]

# Identify numerical and categorical columns
numerical_cols = X.select_dtypes(include=np.number).columns.tolist()
categorical_cols = X.select_dtypes(include='object').columns.tolist()

"""Here, the code defines the target variable (TARGET) as 'loan_status' and the features (FEATURES) as all other columns in the DataFrame. It then separates the data into feature matrix X and target vector y. Finally, it identifies which of the feature columns are numerical (numerical_cols) and which are categorical (categorical_cols).

# 4. Setting up Preprocessing Pipelines
"""

# Preprocessing Pipelines
# Numerical pipeline: Impute missing values (if any) and scale
numerical_transformer = Pipeline(steps=[
    ('scaler', StandardScaler())
])

# Categorical pipeline: One-hot encode
categorical_transformer = Pipeline(steps=[
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

# Create a preprocessor using ColumnTransformer
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_transformer, numerical_cols),
        ('cat', categorical_transformer, categorical_cols)
    ],
    remainder='passthrough'
)

"""### üßπ 4. Setting up Preprocessing Pipelines

This section sets up the **data preprocessing steps** using `sklearn` Pipelines and `ColumnTransformer`. These steps ensure that numerical and categorical data are appropriately transformed before being passed to the machine learning models.

---

#### üî¢ `numerical_transformer`
A pipeline specifically for **numerical features**:
- Uses `StandardScaler()` to standardize features by removing the mean and scaling to unit variance.
- This preprocessing is essential for algorithms like logistic regression or XGBoost that are sensitive to feature scaling.

```python
numerical_transformer = Pipeline(steps=[
    ('scaler', StandardScaler())
])

# 5. Splitting Data and Saving Preprocessor/Feature Names
"""

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Save X_train for getting all_model_columns in AI Agent
# We need to fit the preprocessor first to get the transformed column names
preprocessor.fit(X_train)
X_train_processed_df = pd.DataFrame(preprocessor.transform(X_train),
                                     columns=preprocessor.get_feature_names_out(FEATURES))
X_train_processed_df.to_csv('X_train_processed.csv', index=False)

# Save the scaler and preprocessor for later use
joblib.dump(preprocessor, 'preprocessor.pkl')

"""### ‚úÇÔ∏è 5. Splitting Data & Saving Preprocessor and Features

In this section, we split our dataset into training and testing subsets and prepare the preprocessing pipeline for future use.

---

#### üß™ `train_test_split`
We use `train_test_split` from `sklearn.model_selection` to split the data:
- `test_size=0.2`: Reserves 20% of the data for testing.
- `random_state=42`: Ensures reproducibility of the split.
- `stratify=y`: Maintains the same proportion of target classes (`0` for no risk, `1` for high risk) in both the training and testing sets. This is crucial for classification tasks, especially with **imbalanced datasets**.

```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# 6. Model Training and Evaluation Setup
"""

# --- Model Training and Evaluation ---
print("Starting Machine Learning Model Training and Evaluation...")

# Define models to test
models = {
    "Logistic Regression": LogisticRegression(random_state=42, solver='liblinear', C=0.1),
    "Random Forest": RandomForestClassifier(random_state=42, n_estimators=200, max_depth=10),
    "XGBoost": XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss',
                             n_estimators=200, learning_rate=0.1, max_depth=5)
}

results = {}
best_roc_auc = -1
best_model_name = ""
best_trained_model = None

"""### ‚öôÔ∏è 6. Initializing Model Training and Evaluation

This section sets up the machine learning model training and evaluation process.

---

#### üèÅ Starting the Process
A simple print statement signals the beginning of model training and evaluation:
```python
print("Starting Machine Learning Model Training and Evaluation...")

# 7. Model Training and Evaluation Loop
"""

for name, model in models.items():
    print(f"\nTraining {name}...")

    # Create a full pipeline including preprocessing and the model
    model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                                     ('classifier', model)])

    try:
        model_pipeline.fit(X_train, y_train)
        y_pred = model_pipeline.predict(X_test)
        y_proba = model_pipeline.predict_proba(X_test)[:, 1] # Probability of the positive class (risk)

        # Calculate metrics
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred)
        recall = recall_score(y_test, y_pred)
        roc_auc = roc_auc_score(y_test, y_proba)
        report = classification_report(y_test, y_pred)
        conf_matrix = confusion_matrix(y_test, y_pred)

        # Store results
        results[name] = {
            "accuracy": accuracy,
            "precision": precision,
            "recall": recall,
            "roc_auc": roc_auc,
            "report": report,
            "confusion_matrix": conf_matrix
        }

        # Display results
        print(f"{name} - Accuracy: {accuracy:.4f}")
        print(f"{name} - Precision: {precision:.4f}")
        print(f"{name} - Recall: {recall:.4f}")
        print(f"{name} - ROC AUC: {roc_auc:.4f}")
        print(f"{name} - Classification Report:\n{report}")
        print(f"{name} - Confusion Matrix:\n{conf_matrix}")

        # Select the best model based on ROC AUC
        if roc_auc > best_roc_auc:
            best_roc_auc = roc_auc
            best_model_name = name
            best_trained_model = model_pipeline # Store the entire pipeline

    except Exception as e:
        print(f"Error training {name}: {e}")
        continue

"""### üîÑ 7. Model Training and Evaluation Loop

This is the core part of the machine learning pipeline where each model in the `models` dictionary is trained and evaluated.

---

#### Step-by-step Process:

1. **Iterate over each model:**
   For every model in the dictionary, the code creates a combined pipeline that includes:
   - The previously defined `preprocessor` (handling scaling and encoding).
   - The current classification model.

2. **Train the pipeline:**
   The combined pipeline is trained on the training data (`X_train`, `y_train`). This ensures the preprocessing is applied consistently during training.

3. **Make predictions:**
   - Predict the class labels for the test set (`X_test`) using `.predict()`.
   - Predict the probabilities for the positive class (risk = 1) using `.predict_proba()[:, 1]`.

4. **Calculate evaluation metrics:**
   Using the true labels and predictions, calculate:
   - Accuracy
   - Precision
   - Recall
   - ROC AUC score
   - Detailed classification report
   - Confusion matrix

5. **Store and print the results:**
   Save all metrics in the `results` dictionary and print a summary to the console for each model.

6. **Track the best model:**
   If the current model‚Äôs ROC AUC score is higher than the previous best, update the tracking variables:
   - `best_roc_auc`
   - `best_model_name`
   - `best_trained_model` (store the entire pipeline)

7. **Handle errors:**
   Use a `try...except` block to catch and handle any exceptions during training or evaluation, allowing the loop to continue running through all models even if one fails.

---

```python
for name, model in models.items():
    print(f"\nTraining {name}...")

    # Create a pipeline combining preprocessing and the model
    model_pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', model)
    ])

    try:
        # Train the pipeline on the training data
        model_pipeline.fit(X_train, y_train)

        # Predict class labels on the test data
        y_pred = model_pipeline.predict(X_test)

        # Predict probabilities for the positive class (risk)
        y_proba = model_pipeline.predict_proba(X_test)[:, 1]

        # Calculate performance metrics
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred)
        recall = recall_score(y_test, y_pred)
        roc_auc = roc_auc_score(y_test, y_proba)
        report = classification_report(y_test, y_pred)
        conf_matrix = confusion_matrix(y_test, y_pred)

        # Store results in a dictionary
        results[name] = {
            "accuracy": accuracy,
            "precision": precision,
            "recall": recall,
            "roc_auc": roc_auc,
            "report": report,
            "confusion_matrix": conf_matrix
        }

        # Print metrics to the console
        print(f"{name} - Accuracy: {accuracy:.4f}")
        print(f"{name} - Precision: {precision:.4f}")
        print(f"{name} - Recall: {recall:.4f}")
        print(f"{name} - ROC AUC: {roc_auc:.4f}")
        print(f"{name} - Classification Report:\n{report}")
        print(f"{name} - Confusion Matrix:\n{conf_matrix}")

        # Update best model if current ROC AUC is better
        if roc_auc > best_roc_auc:
            best_roc_auc = roc_auc
            best_model_name = name
            best_trained_model = model_pipeline

    except Exception as e:
        print(f"Error training {name}: {e}")
        continue

# 8. Saving the Best Model and Feature Names
"""

# Save the best model pipeline
if best_trained_model:
    joblib.dump(best_trained_model, 'best_credit_risk_model.pkl')
    # Save the original feature names for SHAP and agent consistency
    original_feature_names = pd.DataFrame(FEATURES, columns=['feature_name'])
    original_feature_names.to_csv('original_feature_names.csv', index=False)
    print(f"\nBest model ({best_model_name}) saved as 'best_credit_risk_model.pkl'.")
    print(f"Original feature names saved as 'original_feature_names.csv'.")
else:
    print("\nNo model was successfully trained or selected.")

print("\nMachine Learning Modeling and Evaluation Complete.")

"""### üîö 8. Save the Best Model and Feature Names

After training and evaluating all models, this section:

- Checks if a `best_trained_model` was found.
- If yes, saves the entire pipeline (including preprocessing and classifier) to `best_credit_risk_model.pkl` using `joblib`.
- Saves the original feature names before preprocessing to `original_feature_names.csv`, which helps with model interpretation later (e.g., using SHAP).
- Prints confirmation messages about the saved model and feature names.
- If no model was successfully trained, prints a message to indicate that.
- Finally, confirms that the modeling and evaluation process is complete.

This ensures you have the best performing model ready for deployment or further analysis, and a record of the original input features.

---

```python
import joblib
import pandas as pd

if best_trained_model is not None:
    # Save the best model pipeline
    joblib.dump(best_trained_model, 'best_credit_risk_model.pkl')
    
    # Save the original feature names before preprocessing
    original_feature_names = X.columns.to_list()
    pd.DataFrame(original_feature_names, columns=['feature_names']).to_csv('original_feature_names.csv', index=False)
    
    print(f"Best model '{best_model_name}' saved as 'best_credit_risk_model.pkl'.")
    print("Original feature names saved to 'original_feature_names.csv'.")
else:
    print("No best model was found or trained successfully.")

print("Model training and evaluation process completed.")

## Sources

- [How to Leverage ChatGPT's Code Interpreter Feature for Data Science Projects](https://ai.plainenglish.io/how-to-leverage-chatgpts-code-interpreter-feature-for-data-science-projects-757e2c0deb77)
- [ImmoEliza API (GitHub)](https://github.com/kaiyungtan/ImmoEliza-API)
- [HR Analysis (GitHub)](https://github.com/dbokan1/HRAnalysis)
- [Credit Score (GitHub)](https://github.com/michaelrantisi/credit-score)
- [Credit Card Approval (GitHub)](https://github.com/Rachelfanye/Credit-Card-Approval)
- [Project2 (GitHub)](https://github.com/Rabih1996/Project2)
- [Spaceship Titanic: A Complete Guide (Kaggle)](https://www.kaggle.com/code/samuelcortinhas/spaceship-titanic-a-complete-guide)
- [Building a Credit Risk Model: A Step-by-Step Guide with Python](https://python.plainenglish.io/building-a-credit-risk-model-a-step-by-step-guide-with-python-3e62beabfe9a)
- [Enhancing Wildfire Prediction Accuracy Through Fourier Transform-Based Lagged Features](https://pub.aimind.so/enhancing-wildfire-prediction-accuracy-through-fourier-transform-based-lagged-features-in-d23d23592a34)
"""